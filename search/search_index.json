{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Jacob Rider Professional Summary I am a math and data enthusiast looking for a position where I can build probabilistic models of complex data in order to inform decision making (with a little bit of help from generative AI). In my most recent jobs, I learned the extract, transform, and load (ETL) process using a variety of methods. I also have experience creating dashboards and KPIs using Tableau and Excel. I believe these experiences uniquely position me to own the data modeling process from end-to-end. Skills: Python, SQL, AWS, Tableau, Excel Passions: Generative AI, probabilistic programming, and data modeling Soft Skills: Concise and courteous communication Hobbies: Board games, travel, and food jacob.rider34@gmail.com | LinkedIn | GitHub | Website Experience | Education | Skills | Projects | Contact","title":"Home"},{"location":"#jacob-rider","text":"","title":"Jacob Rider"},{"location":"#professional-summary","text":"I am a math and data enthusiast looking for a position where I can build probabilistic models of complex data in order to inform decision making (with a little bit of help from generative AI). In my most recent jobs, I learned the extract, transform, and load (ETL) process using a variety of methods. I also have experience creating dashboards and KPIs using Tableau and Excel. I believe these experiences uniquely position me to own the data modeling process from end-to-end. Skills: Python, SQL, AWS, Tableau, Excel Passions: Generative AI, probabilistic programming, and data modeling Soft Skills: Concise and courteous communication Hobbies: Board games, travel, and food jacob.rider34@gmail.com | LinkedIn | GitHub | Website Experience | Education | Skills | Projects | Contact","title":"Professional Summary"},{"location":"baseball_pitch_predictor/","text":"Baseball Pitch Predictor View Project on GitHub Technologies Used Python Jax Flax Project Overview Created a predictive model to analyze and forecast baseball pitch types based on historical pitch data. Key Features Analysis of pitch frequency over varying time periods to predict the next pitch. Imports import pandas as pd import numpy as np from jax import numpy as jnp from typing import Tuple, Dict, List import time Functions normalize_counts def normalize_counts(pitch_counts: np.ndarray) -> np.ndarray: \"\"\" Normalize the pitch counts to get a distribution proportion. Parameters: - pitch_counts: Array of pitch counts. Returns: - np.ndarray: Normalized distribution of pitch counts. \"\"\" efficient_pitch_distribution def efficient_pitch_distribution(df: pd.DataFrame, pitch_types: List[str], filter_conditions: Dict[str, str]) -> np.ndarray: \"\"\" Calculate and normalize the distribution of pitch types, excluding the current event. \"\"\" Example Usage # In progress","title":"Baseball Pitch Predictor"},{"location":"baseball_pitch_predictor/#baseball-pitch-predictor","text":"View Project on GitHub","title":"Baseball Pitch Predictor"},{"location":"baseball_pitch_predictor/#technologies-used","text":"Python Jax Flax","title":"Technologies Used"},{"location":"baseball_pitch_predictor/#project-overview","text":"Created a predictive model to analyze and forecast baseball pitch types based on historical pitch data.","title":"Project Overview"},{"location":"baseball_pitch_predictor/#key-features","text":"Analysis of pitch frequency over varying time periods to predict the next pitch.","title":"Key Features"},{"location":"baseball_pitch_predictor/#imports","text":"import pandas as pd import numpy as np from jax import numpy as jnp from typing import Tuple, Dict, List import time","title":"Imports"},{"location":"baseball_pitch_predictor/#functions","text":"","title":"Functions"},{"location":"baseball_pitch_predictor/#normalize_counts","text":"def normalize_counts(pitch_counts: np.ndarray) -> np.ndarray: \"\"\" Normalize the pitch counts to get a distribution proportion. Parameters: - pitch_counts: Array of pitch counts. Returns: - np.ndarray: Normalized distribution of pitch counts. \"\"\"","title":"normalize_counts"},{"location":"baseball_pitch_predictor/#efficient_pitch_distribution","text":"def efficient_pitch_distribution(df: pd.DataFrame, pitch_types: List[str], filter_conditions: Dict[str, str]) -> np.ndarray: \"\"\" Calculate and normalize the distribution of pitch types, excluding the current event. \"\"\"","title":"efficient_pitch_distribution"},{"location":"baseball_pitch_predictor/#example-usage","text":"# In progress","title":"Example Usage"},{"location":"data_tools/","text":"Data Tools for Economic Research View Project on GitHub Technologies Used Python SQL Project Overview Developed a suite of data analysis tools tailored for economic research, facilitating the efficient cleaning, processing, and ingestion of economic and financial API data into a SQLite database. Key Features Automated data cleaning and processing workflows. Ingestion of diverse economic and financial data into a unified database. Simplified access to clean, processed data for economic research and analysis. Imports import sqlite3 import requests import pandas as pd from sklearn.preprocessing import StandardScaler from typing import List, Optional Classes DataIngestor class DataIngestor: \"\"\" A class to ingest and process financial data from a SQLite database. \"\"\" def __init__(self, db_path: str, table_names: list, min_date: str): \"\"\" Initialize the DataIngestor with database path, table names, and minimum date. Args: db_path (str): Path to the SQLite database. table_names (list): List of table names to process. min_date (str): Minimum date for filtering data. \"\"\" self.db_path = db_path self.table_names = table_names self.min_date = min_date DataFetcher class DataFetcher: \"\"\" A class to fetch and insert financial and economic data into a SQLite database. Attributes: db_path (str): The file path for the SQLite database. \"\"\" def __init__(self, db_path: str) -> None: \"\"\" Initialize the DataFetcher class. Args: db_path (str): The file path for the SQLite database. \"\"\" self.db_path = db_path Methods DataFetcher Methods create_table() def create_table(self, table_name: str, columns: List[str], is_stock: bool) -> None: \"\"\" Create a table in the SQLite database. Args: table_name (str): The name of the table to create. columns (List[str]): A list of column names for the table. isStock (bool): Indicator of whether the data is stock data (True) or economic data (False). \"\"\" fetch_and_insert_stock_data() def fetch_and_insert_stock_data( self, stock_ticker: str, api_key: str, report_link: str, from_date: str, to_date: str, ) -> None: \"\"\" Fetch stock data from an API and insert it into the database. Args: stock_ticker (str): The stock ticker symbol. api_key (str): The API key for authentication. report_link (str): The endpoint link for the API request. from_date (str): Start date for the data. to_date (str): End date for the data. \"\"\" fetch_and_insert_economic_data() def fetch_and_insert_economic_data(self, api_key: str, report_link: str) -> None: \"\"\" Fetch economic data from an API and insert it into the database. Args: api_key (str): The API key for authentication. report_link (str): The endpoint link for the API request. \"\"\" _insert_data() def _insert_data( self, table_name: str, columns: List[str], data: List[dict], ticker: Optional[str] = None, ) -> None: \"\"\" Insert data into a specified table in the database. Args: table_name (str): The name of the table to insert data into. columns (List[str]): The column names for data insertion. data (List[Dict]): The data to be inserted. ticker (Optional[str]): The stock ticker symbol. Defaults to None. \"\"\" DataIngestor Methods get_column_names() def get_column_names(self, conn: sqlite3.Connection, table_name: str) -> list: \"\"\" Retrieve column names for a given table in the database. Args: conn (sqlite3.Connection): A connection object to the SQLite database. table_name (str): Name of the table to retrieve columns from. Returns: list: A list of column names. \"\"\" fetch_and_process_data() def fetch_and_process_data(self) -> list: \"\"\" Fetch and process data from the database for each table. Returns: list: A list of processed pandas DataFrames. \"\"\" scale_data() def scale_data(self, dfs: list) -> pd.DataFrame: \"\"\" Scale the data using StandardScaler. Args: dfs (list): List of pandas DataFrames to scale. Returns: pd.DataFrame: A DataFrame of scaled features. \"\"\" utils process_data() def process_data(db_path: str, table_names: list, min_date: str) -> tuple: \"\"\" Process and scale data from the database. Args: db_path (str): Path to the SQLite database. table_names (list): List of table names to process. min_date (str): Minimum date for filtering data. Returns: tuple: A tuple containing list of DataFrames and scaled DataFrame. \"\"\" drop_table() def drop_table(db_path: str, table_name: str) -> None: \"\"\" Drop a table from the database. Args: db_path (str): Path to the SQLite database. table_name (str): Name of the table to be dropped. \"\"\" fetch_stocks_data() def fetch_stocks_data( db_path: str, stocks: List[str], api_key: str, report_link: str ) -> None: \"\"\" Fetch and insert stock data for multiple stocks into the database. Args: db_path (str): The file path for the SQLite database. stocks (List[str]): A list of stock ticker symbols. api_key (str): The API key for authentication. report_link (str): The endpoint link for the API request. fetch_economic_data() def fetch_economic_data(db_path: str, table_names: List[str], api_key: str) -> None: \"\"\" Fetch and insert economic data for multiple series into the database. Args: db_path (str): The file path for the SQLite database. table_names (list[str]): A list of economic data series identifiers. api_key (str): The API key for authentication. \"\"\"","title":"Data Tools for Economic Research"},{"location":"data_tools/#data-tools-for-economic-research","text":"View Project on GitHub","title":"Data Tools for Economic Research"},{"location":"data_tools/#technologies-used","text":"Python SQL","title":"Technologies Used"},{"location":"data_tools/#project-overview","text":"Developed a suite of data analysis tools tailored for economic research, facilitating the efficient cleaning, processing, and ingestion of economic and financial API data into a SQLite database.","title":"Project Overview"},{"location":"data_tools/#key-features","text":"Automated data cleaning and processing workflows. Ingestion of diverse economic and financial data into a unified database. Simplified access to clean, processed data for economic research and analysis.","title":"Key Features"},{"location":"data_tools/#imports","text":"import sqlite3 import requests import pandas as pd from sklearn.preprocessing import StandardScaler from typing import List, Optional","title":"Imports"},{"location":"data_tools/#classes","text":"","title":"Classes"},{"location":"data_tools/#dataingestor","text":"class DataIngestor: \"\"\" A class to ingest and process financial data from a SQLite database. \"\"\" def __init__(self, db_path: str, table_names: list, min_date: str): \"\"\" Initialize the DataIngestor with database path, table names, and minimum date. Args: db_path (str): Path to the SQLite database. table_names (list): List of table names to process. min_date (str): Minimum date for filtering data. \"\"\" self.db_path = db_path self.table_names = table_names self.min_date = min_date","title":"DataIngestor"},{"location":"data_tools/#datafetcher","text":"class DataFetcher: \"\"\" A class to fetch and insert financial and economic data into a SQLite database. Attributes: db_path (str): The file path for the SQLite database. \"\"\" def __init__(self, db_path: str) -> None: \"\"\" Initialize the DataFetcher class. Args: db_path (str): The file path for the SQLite database. \"\"\" self.db_path = db_path","title":"DataFetcher"},{"location":"data_tools/#methods","text":"","title":"Methods"},{"location":"data_tools/#datafetcher-methods","text":"","title":"DataFetcher Methods"},{"location":"data_tools/#create_table","text":"def create_table(self, table_name: str, columns: List[str], is_stock: bool) -> None: \"\"\" Create a table in the SQLite database. Args: table_name (str): The name of the table to create. columns (List[str]): A list of column names for the table. isStock (bool): Indicator of whether the data is stock data (True) or economic data (False). \"\"\"","title":"create_table()"},{"location":"data_tools/#fetch_and_insert_stock_data","text":"def fetch_and_insert_stock_data( self, stock_ticker: str, api_key: str, report_link: str, from_date: str, to_date: str, ) -> None: \"\"\" Fetch stock data from an API and insert it into the database. Args: stock_ticker (str): The stock ticker symbol. api_key (str): The API key for authentication. report_link (str): The endpoint link for the API request. from_date (str): Start date for the data. to_date (str): End date for the data. \"\"\"","title":"fetch_and_insert_stock_data()"},{"location":"data_tools/#fetch_and_insert_economic_data","text":"def fetch_and_insert_economic_data(self, api_key: str, report_link: str) -> None: \"\"\" Fetch economic data from an API and insert it into the database. Args: api_key (str): The API key for authentication. report_link (str): The endpoint link for the API request. \"\"\"","title":"fetch_and_insert_economic_data()"},{"location":"data_tools/#_insert_data","text":"def _insert_data( self, table_name: str, columns: List[str], data: List[dict], ticker: Optional[str] = None, ) -> None: \"\"\" Insert data into a specified table in the database. Args: table_name (str): The name of the table to insert data into. columns (List[str]): The column names for data insertion. data (List[Dict]): The data to be inserted. ticker (Optional[str]): The stock ticker symbol. Defaults to None. \"\"\"","title":"_insert_data()"},{"location":"data_tools/#dataingestor-methods","text":"","title":"DataIngestor Methods"},{"location":"data_tools/#get_column_names","text":"def get_column_names(self, conn: sqlite3.Connection, table_name: str) -> list: \"\"\" Retrieve column names for a given table in the database. Args: conn (sqlite3.Connection): A connection object to the SQLite database. table_name (str): Name of the table to retrieve columns from. Returns: list: A list of column names. \"\"\"","title":"get_column_names()"},{"location":"data_tools/#fetch_and_process_data","text":"def fetch_and_process_data(self) -> list: \"\"\" Fetch and process data from the database for each table. Returns: list: A list of processed pandas DataFrames. \"\"\"","title":"fetch_and_process_data()"},{"location":"data_tools/#scale_data","text":"def scale_data(self, dfs: list) -> pd.DataFrame: \"\"\" Scale the data using StandardScaler. Args: dfs (list): List of pandas DataFrames to scale. Returns: pd.DataFrame: A DataFrame of scaled features. \"\"\"","title":"scale_data()"},{"location":"data_tools/#utils","text":"","title":"utils"},{"location":"data_tools/#process_data","text":"def process_data(db_path: str, table_names: list, min_date: str) -> tuple: \"\"\" Process and scale data from the database. Args: db_path (str): Path to the SQLite database. table_names (list): List of table names to process. min_date (str): Minimum date for filtering data. Returns: tuple: A tuple containing list of DataFrames and scaled DataFrame. \"\"\"","title":"process_data()"},{"location":"data_tools/#drop_table","text":"def drop_table(db_path: str, table_name: str) -> None: \"\"\" Drop a table from the database. Args: db_path (str): Path to the SQLite database. table_name (str): Name of the table to be dropped. \"\"\"","title":"drop_table()"},{"location":"data_tools/#fetch_stocks_data","text":"def fetch_stocks_data( db_path: str, stocks: List[str], api_key: str, report_link: str ) -> None: \"\"\" Fetch and insert stock data for multiple stocks into the database. Args: db_path (str): The file path for the SQLite database. stocks (List[str]): A list of stock ticker symbols. api_key (str): The API key for authentication. report_link (str): The endpoint link for the API request.","title":"fetch_stocks_data()"},{"location":"data_tools/#fetch_economic_data","text":"def fetch_economic_data(db_path: str, table_names: List[str], api_key: str) -> None: \"\"\" Fetch and insert economic data for multiple series into the database. Args: db_path (str): The file path for the SQLite database. table_names (list[str]): A list of economic data series identifiers. api_key (str): The API key for authentication. \"\"\"","title":"fetch_economic_data()"},{"location":"education/","text":"Education Bachelor of Science in Mathematics and Economics Georgia State University, Atlanta, GA | Class of 2020 Completed a comprehensive curriculum focusing on rigorous math courses, quantitative analysis, statistical methods, and economic theory. Led a team project modeling asset bubbles with physics equations, using Bloomberg data for model calibration. Collaborated with the Molkov Theoretical Neuroscience Research Group by developing visualizations for experimental data using Matplotlib and Python to model the feedback mechanisms that underlie the cardio-respiratory system. Certifications Tableau Data Analyst Tableau Desktop Specialist","title":"Education"},{"location":"education/#education","text":"","title":"Education"},{"location":"education/#bachelor-of-science-in-mathematics-and-economics","text":"Georgia State University, Atlanta, GA | Class of 2020 Completed a comprehensive curriculum focusing on rigorous math courses, quantitative analysis, statistical methods, and economic theory. Led a team project modeling asset bubbles with physics equations, using Bloomberg data for model calibration. Collaborated with the Molkov Theoretical Neuroscience Research Group by developing visualizations for experimental data using Matplotlib and Python to model the feedback mechanisms that underlie the cardio-respiratory system.","title":"Bachelor of Science in Mathematics and Economics"},{"location":"education/#certifications","text":"Tableau Data Analyst Tableau Desktop Specialist","title":"Certifications"},{"location":"experience/","text":"Professional Experience Associate Data Engineer Delta Air Lines Atlanta, GA | June 2022 \u2013 Present Developed and maintained scalable data pipelines and implemented ETL processes to support analytics and business intelligence (BI) reporting. Collaborated with cross-functional teams to understand data needs, leading the design and implementation of Tableau dashboards. Utilized Python and SQL for data manipulation, cleaning, and analysis, improving data accuracy and utility across departments. Played a key role in the migration of legacy systems to AWS, ensuring minimal downtime and data integrity. Logistics Document Specialist Mercedes-Benz USA, LLC Atlanta, GA | March 2021 \u2013 December 2021 Managed and streamlined the documentation process for logistics operations, enhancing the efficiency of shipment and delivery schedules. Created VBA macros that query the SAP HANA database and automatically generate KPIs in order to drive monthly performance reviews for each carrier. Built and implemented a Python script to parse through emails based on a given set of keywords in order to improve data quality and reduce time spent aggregating VINs and PO numbers. Automated routine management reports using Excel, VBA, SAP, and Python saving approximately 50 hours per month for key logistics personnel. Contributed to the development of training materials and procedures for new team members, ensuring consistent and accurate document handling.","title":"Experience"},{"location":"experience/#professional-experience","text":"","title":"Professional Experience"},{"location":"experience/#associate-data-engineer","text":"","title":"Associate Data Engineer"},{"location":"experience/#delta-air-lines","text":"Atlanta, GA | June 2022 \u2013 Present Developed and maintained scalable data pipelines and implemented ETL processes to support analytics and business intelligence (BI) reporting. Collaborated with cross-functional teams to understand data needs, leading the design and implementation of Tableau dashboards. Utilized Python and SQL for data manipulation, cleaning, and analysis, improving data accuracy and utility across departments. Played a key role in the migration of legacy systems to AWS, ensuring minimal downtime and data integrity.","title":"Delta Air Lines"},{"location":"experience/#logistics-document-specialist","text":"","title":"Logistics Document Specialist"},{"location":"experience/#mercedes-benz-usa-llc","text":"Atlanta, GA | March 2021 \u2013 December 2021 Managed and streamlined the documentation process for logistics operations, enhancing the efficiency of shipment and delivery schedules. Created VBA macros that query the SAP HANA database and automatically generate KPIs in order to drive monthly performance reviews for each carrier. Built and implemented a Python script to parse through emails based on a given set of keywords in order to improve data quality and reduce time spent aggregating VINs and PO numbers. Automated routine management reports using Excel, VBA, SAP, and Python saving approximately 50 hours per month for key logistics personnel. Contributed to the development of training materials and procedures for new team members, ensuring consistent and accurate document handling.","title":"Mercedes-Benz USA, LLC"},{"location":"prob_prog_tools/","text":"Probabilistic Programming Tools View Project on GitHub Technologies Used Python NumPy Jax NumPyro Project Overview Designed tools that simulate a random levy process and then uses NumPyro to infer the parameters used to simulate those processes. Key Features Simulation of processes that resemble stock price movements using random levy processes. Parameter inference with NumPyro to understand underlying market dynamics. Imports from scipy.stats import levy_stable from jax.scipy.linalg import cholesky from typing import Dict, List, Tuple import os from typing import Any, Dict import jax import jax.numpy as jnp import matplotlib.pyplot as plt import numpyro import numpyro.distributions as dist import seaborn as sns from numpyro.infer import MCMC, NUTS Classes StockMarketSimulator class StockMarketSimulator: \"\"\" A simulator for stock market prices using Levy processes with JAX for computation and Pareto-distributed initial prices using NumPy. Attributes: n_industries (int): Number of industries. n_stocks_per_industry (int): Number of stocks per industry. base_stock_price (float): Base stock price for scaling initial prices. industries (List[str]): List of industry names. stocks (List[str]): List of stock symbols. stock_prices (pd.DataFrame): DataFrame to store simulated stock prices. seed (int): Int derived through os for true random state key (jax.random.PRNGKey): JAX PRNG key for random number generation. industry_map (Dict[str, str]): Mapping of stocks to their respective industries. alpha_params (Dict[str, float]): Alpha parameter for each industry. beta_params (Dict[str, float]): Beta parameter for each industry. pareto_shapes (Dict[str, float]): Pareto shape parameter for each industry. \"\"\" Methods init () def __init__(self, n_industries: int = 8, n_stocks_per_industry: int = 10, base_stock_price: float = 100) -> None: \"\"\" Initialize the stock market simulator with specified parameters. Args: n_industries (int): The number of industries to simulate. n_stocks_per_industry (int): The number of stocks per industry. base_stock_price (float): The base stock price for scaling initial prices. \"\"\" _initialize_prices() def _initialize_prices(self) -> None: \"\"\"Initialize the stock prices using Pareto distribution for each industry.\"\"\" _simulate_stock_prices() def simulate_stock_prices(self, n_days: int = 252) -> pd.DataFrame: \"\"\" Simulate stock prices over a given number of days. Args: n_days (int): The number of days to simulate stock prices. Returns: pd.DataFrame: A DataFrame containing the simulated stock prices. \"\"\" _apply_correlation def _apply_correlation(self, increments: np.ndarray) -> np.ndarray: \"\"\" Apply a correlation matrix to the increments using Cholesky decomposition. Args: increments (np.ndarray): An array of increments to apply correlation to. Returns: np.ndarray: Correlated increments after applying the correlation matrix. \"\"\" Functions plot_posteriors() def plot_posteriors(posterior_samples: Dict[str, jnp.ndarray], industry: str) -> None: \"\"\" Plots the posterior distributions for a given industry. Args: posterior_samples: Samples from the posterior distribution as a dictionary where keys are parameter names. industry (str): The name of the industry for which the posterior distributions are plotted. \"\"\" run_bayesian_inference() def run_bayesian_inference(simulator: DI.StockMarketSimulator, n_samples: int = 500, n_warmup: int = 100) -> None: \"\"\" Runs Bayesian inference for each industry and plots the posterior distributions. Args: simulator: An instance of StockMarketSimulator containing stock prices and industry mappings. n_samples (int): Number of samples to draw from the posterior distribution. n_warmup (int): Number of warmup steps for the sampler. \"\"\" plot_stock_prices() def plot_stock_prices(simulator: DI.StockMarketSimulator) -> None: \"\"\" Plot the simulated stock prices for all stocks in the simulation. Args: simulator (DI.StockMarketSimulator): An instance of the StockMarketSimulator class. This function generates a line plot for each stock across the simulated days and saves the plot to a file named 'simulated_stock_prices.png' in the 'plots' directory. \"\"\" plot_stock_prices_by_industry() def plot_stock_prices_by_industry(simulator: DI.StockMarketSimulator) -> None: \"\"\" Plot the simulated stock prices for each industry separately. Args: simulator (DI.StockMarketSimulator): An instance of the StockMarketSimulator class. This function generates a line plot for each stock within an industry across the simulated days and saves each industry's plot to a separate file in the 'plots' directory, named 'simulated_stock_price_by_[industry].png'. \"\"\" Example Usage def main() -> None: \"\"\" Main function to initialize the simulator, run the stock price simulation, and plot the results. \"\"\" simulator = DI.StockMarketSimulator() run_bayesian_inference(simulator) simulator.simulate_stock_prices() plot_stock_prices(simulator) plot_stock_prices_by_industry(simulator) if __name__ == \"__main__\": main()","title":"Probabilistic Programming Tools"},{"location":"prob_prog_tools/#probabilistic-programming-tools","text":"View Project on GitHub","title":"Probabilistic Programming Tools"},{"location":"prob_prog_tools/#technologies-used","text":"Python NumPy Jax NumPyro","title":"Technologies Used"},{"location":"prob_prog_tools/#project-overview","text":"Designed tools that simulate a random levy process and then uses NumPyro to infer the parameters used to simulate those processes.","title":"Project Overview"},{"location":"prob_prog_tools/#key-features","text":"Simulation of processes that resemble stock price movements using random levy processes. Parameter inference with NumPyro to understand underlying market dynamics.","title":"Key Features"},{"location":"prob_prog_tools/#imports","text":"from scipy.stats import levy_stable from jax.scipy.linalg import cholesky from typing import Dict, List, Tuple import os from typing import Any, Dict import jax import jax.numpy as jnp import matplotlib.pyplot as plt import numpyro import numpyro.distributions as dist import seaborn as sns from numpyro.infer import MCMC, NUTS","title":"Imports"},{"location":"prob_prog_tools/#classes","text":"","title":"Classes"},{"location":"prob_prog_tools/#stockmarketsimulator","text":"class StockMarketSimulator: \"\"\" A simulator for stock market prices using Levy processes with JAX for computation and Pareto-distributed initial prices using NumPy. Attributes: n_industries (int): Number of industries. n_stocks_per_industry (int): Number of stocks per industry. base_stock_price (float): Base stock price for scaling initial prices. industries (List[str]): List of industry names. stocks (List[str]): List of stock symbols. stock_prices (pd.DataFrame): DataFrame to store simulated stock prices. seed (int): Int derived through os for true random state key (jax.random.PRNGKey): JAX PRNG key for random number generation. industry_map (Dict[str, str]): Mapping of stocks to their respective industries. alpha_params (Dict[str, float]): Alpha parameter for each industry. beta_params (Dict[str, float]): Beta parameter for each industry. pareto_shapes (Dict[str, float]): Pareto shape parameter for each industry. \"\"\"","title":"StockMarketSimulator"},{"location":"prob_prog_tools/#methods","text":"","title":"Methods"},{"location":"prob_prog_tools/#init","text":"def __init__(self, n_industries: int = 8, n_stocks_per_industry: int = 10, base_stock_price: float = 100) -> None: \"\"\" Initialize the stock market simulator with specified parameters. Args: n_industries (int): The number of industries to simulate. n_stocks_per_industry (int): The number of stocks per industry. base_stock_price (float): The base stock price for scaling initial prices. \"\"\"","title":"init()"},{"location":"prob_prog_tools/#_initialize_prices","text":"def _initialize_prices(self) -> None: \"\"\"Initialize the stock prices using Pareto distribution for each industry.\"\"\"","title":"_initialize_prices()"},{"location":"prob_prog_tools/#_simulate_stock_prices","text":"def simulate_stock_prices(self, n_days: int = 252) -> pd.DataFrame: \"\"\" Simulate stock prices over a given number of days. Args: n_days (int): The number of days to simulate stock prices. Returns: pd.DataFrame: A DataFrame containing the simulated stock prices. \"\"\"","title":"_simulate_stock_prices()"},{"location":"prob_prog_tools/#_apply_correlation","text":"def _apply_correlation(self, increments: np.ndarray) -> np.ndarray: \"\"\" Apply a correlation matrix to the increments using Cholesky decomposition. Args: increments (np.ndarray): An array of increments to apply correlation to. Returns: np.ndarray: Correlated increments after applying the correlation matrix. \"\"\"","title":"_apply_correlation"},{"location":"prob_prog_tools/#functions","text":"","title":"Functions"},{"location":"prob_prog_tools/#plot_posteriors","text":"def plot_posteriors(posterior_samples: Dict[str, jnp.ndarray], industry: str) -> None: \"\"\" Plots the posterior distributions for a given industry. Args: posterior_samples: Samples from the posterior distribution as a dictionary where keys are parameter names. industry (str): The name of the industry for which the posterior distributions are plotted. \"\"\"","title":"plot_posteriors()"},{"location":"prob_prog_tools/#run_bayesian_inference","text":"def run_bayesian_inference(simulator: DI.StockMarketSimulator, n_samples: int = 500, n_warmup: int = 100) -> None: \"\"\" Runs Bayesian inference for each industry and plots the posterior distributions. Args: simulator: An instance of StockMarketSimulator containing stock prices and industry mappings. n_samples (int): Number of samples to draw from the posterior distribution. n_warmup (int): Number of warmup steps for the sampler. \"\"\"","title":"run_bayesian_inference()"},{"location":"prob_prog_tools/#plot_stock_prices","text":"def plot_stock_prices(simulator: DI.StockMarketSimulator) -> None: \"\"\" Plot the simulated stock prices for all stocks in the simulation. Args: simulator (DI.StockMarketSimulator): An instance of the StockMarketSimulator class. This function generates a line plot for each stock across the simulated days and saves the plot to a file named 'simulated_stock_prices.png' in the 'plots' directory. \"\"\"","title":"plot_stock_prices()"},{"location":"prob_prog_tools/#plot_stock_prices_by_industry","text":"def plot_stock_prices_by_industry(simulator: DI.StockMarketSimulator) -> None: \"\"\" Plot the simulated stock prices for each industry separately. Args: simulator (DI.StockMarketSimulator): An instance of the StockMarketSimulator class. This function generates a line plot for each stock within an industry across the simulated days and saves each industry's plot to a separate file in the 'plots' directory, named 'simulated_stock_price_by_[industry].png'. \"\"\"","title":"plot_stock_prices_by_industry()"},{"location":"prob_prog_tools/#example-usage","text":"def main() -> None: \"\"\" Main function to initialize the simulator, run the stock price simulation, and plot the results. \"\"\" simulator = DI.StockMarketSimulator() run_bayesian_inference(simulator) simulator.simulate_stock_prices() plot_stock_prices(simulator) plot_stock_prices_by_industry(simulator) if __name__ == \"__main__\": main()","title":"Example Usage"},{"location":"projects/","text":"Projects TI4 Combat Simulator Technologies Used : Python, Jax, NumPyro Developed a combat simulator for the board game \"Twilight Imperium 4th Edition\" (TI4), utilizing Monte Carlo and probability theory to model the distribution of outcomes for in-game combat scenarios. Baseball Pitch Predictor Technologies Used : Python, Jax, Flax Created a predictive model to analyze and forecast baseball pitch types based on historical pitch data. Probabilistic Programming Tools Technologies Used : Python, NumPy, Jax, NumPyro Designed a stock market simulation tool that simulates a random levy process and then uses NumPyro infers the parameters used to simulate those processes. Data Tools for Economic Research Technologies Used : Python, SQL Developed a suite of data analysis tools tailored for economic research and the cleaning and ingestion of economic and financial API data into a SQLite database.","title":"Projects"},{"location":"projects/#projects","text":"","title":"Projects"},{"location":"projects/#ti4-combat-simulator","text":"Technologies Used : Python, Jax, NumPyro Developed a combat simulator for the board game \"Twilight Imperium 4th Edition\" (TI4), utilizing Monte Carlo and probability theory to model the distribution of outcomes for in-game combat scenarios.","title":"TI4 Combat Simulator"},{"location":"projects/#baseball-pitch-predictor","text":"Technologies Used : Python, Jax, Flax Created a predictive model to analyze and forecast baseball pitch types based on historical pitch data.","title":"Baseball Pitch Predictor"},{"location":"projects/#probabilistic-programming-tools","text":"Technologies Used : Python, NumPy, Jax, NumPyro Designed a stock market simulation tool that simulates a random levy process and then uses NumPyro infers the parameters used to simulate those processes.","title":"Probabilistic Programming Tools"},{"location":"projects/#data-tools-for-economic-research","text":"Technologies Used : Python, SQL Developed a suite of data analysis tools tailored for economic research and the cleaning and ingestion of economic and financial API data into a SQLite database.","title":"Data Tools for Economic Research"},{"location":"skills/","text":"Skills Python : Proficient in Python programming for end-to-end data processing and modeling Pandas NumPy Jax NumPyro SQL : Experienced in SQL for database management, querying, and data manipulation AWS : Familiarity with AWS services such as lambda, s3, and athena Tableau : Skilled in using Tableau to inform decision makers with visually appealing and insightful dashboards Excel : Advanced proficiency in Excel Passions Probabilistic Programming : Fascinated by the application of probabilistic programming for building complex models and simulations Generative AI : Interested in exploring the capabilities of generative AI for creating new content and solving unique problems Data Modeling : Passionate about constructing accurate data models to uncover insights and inform strategic decision-making","title":"Skills"},{"location":"skills/#skills","text":"Python : Proficient in Python programming for end-to-end data processing and modeling Pandas NumPy Jax NumPyro SQL : Experienced in SQL for database management, querying, and data manipulation AWS : Familiarity with AWS services such as lambda, s3, and athena Tableau : Skilled in using Tableau to inform decision makers with visually appealing and insightful dashboards Excel : Advanced proficiency in Excel","title":"Skills"},{"location":"skills/#passions","text":"Probabilistic Programming : Fascinated by the application of probabilistic programming for building complex models and simulations Generative AI : Interested in exploring the capabilities of generative AI for creating new content and solving unique problems Data Modeling : Passionate about constructing accurate data models to uncover insights and inform strategic decision-making","title":"Passions"},{"location":"ti4_combat_simulator/","text":"TI4 Combat Simulator View Project on GitHub Technologies Used Python Jax Project Background Twilight Imperium (TI4) is a grand strategy board game known for its intricate diplomacy, expansive empire-building, and epic space battles. TI4's combat involves a blend of strategic planning and randomness. While unit statistics and player decisions play a significant role, the combat system incorporates elements of randomness through dice rolls. Project Overview This combat simulator for TI4 utilizes Monte Carlo and probability theory to model the distribution of outcomes for in-game combat scenarios. This tool helps players understand the potential outcomes of their strategic decisions in combat, aiding in planning and execution during gameplay. Key Features Monte Carlo simulation methods to predict combat outcomes. Probability theory to sample from combinations of probabilities. ti4_functions This document describes a set of functions for simulating combat scenarios using JAX. Imports import jax import jax.numpy as jnp from jax import random import os from typing import Dict, Tuple, Any Types KeyType = Tuple[int, float] SideType = Dict[KeyType, int] RNGKey = Any Functions apply_hits def apply_hits(side: SideType, hits_scored: int, rng_key: RNGKey) -> SideType: \"\"\" Apply hits to a side with JAX, prioritizing dice with lower hit probabilities and lower health. Incorporates randomness in selecting dice within the same priority level to take hits. Accepts an RNG key for reproducible randomness. Parameters: side (SideType): Dictionary representing the side's units and their stats. hits_scored (int): Number of hits to apply to the side. rng_key (RNGKey): JAX random key for generating random numbers. Returns: SideType: Updated side after applying hits. \"\"\" simulate_combat_round_jax def simulate_combat_round_jax(side_a: SideType, side_b: SideType, rng_key: RNGKey) -> Tuple[SideType, SideType]: \"\"\" Simulates a single round of combat between two sides using JAX. Parameters: side_a (SideType): First combatant side. side_b (SideType): Second combatant side. rng_key (RNGKey): JAX random key for generating random numbers. Returns: Tuple[SideType, SideType]: Updated states of side_a and side_b after combat. \"\"\" run_combat_until_elimination def simulate_combat_round_jax(side_a: SideType, side_b: SideType, rng_key: RNGKey) -> Tuple[SideType, SideType]: \"\"\" Simulates a single round of combat between two sides using JAX. Parameters: side_a (SideType): First combatant side. side_b (SideType): Second combatant side. rng_key (RNGKey): JAX random key for generating random numbers. Returns: Tuple[SideType, SideType]: Updated states of side_a and side_b after combat. \"\"\" monte_carlo_combat_simulation def monte_carlo_combat_simulation(initial_side_a: SideType, initial_side_b: SideType, num_simulations: int = 1000) -> Dict[str, float]: \"\"\" Performs a Monte Carlo simulation of combat between two sides over a specified number of simulations to estimate outcome probabilities. Parameters: initial_side_a (SideType): Initial state of side A. initial_side_b (SideType): Initial state of side B. num_simulations (int): Number of simulations to run. Returns: Dict[str, float]: Probabilities of different outcomes. \"\"\" Example Usage The following is an example of 2 dreadnaughts, each with 2 health hitting 60% of the time fighting vs 6 fighters, each with 1 health hitting 20% of the time. initial_side_a = {(2, 0.6): 3} initial_side_b = {(1, 0.2): 6} num_simulations = 10000 probabilities = monte_carlo_combat_simulation(initial_side_a, initial_side_b, num_simulations) print(probabilities)","title":"TI4 Combat Simulator"},{"location":"ti4_combat_simulator/#ti4-combat-simulator","text":"View Project on GitHub","title":"TI4 Combat Simulator"},{"location":"ti4_combat_simulator/#technologies-used","text":"Python Jax","title":"Technologies Used"},{"location":"ti4_combat_simulator/#project-background","text":"Twilight Imperium (TI4) is a grand strategy board game known for its intricate diplomacy, expansive empire-building, and epic space battles. TI4's combat involves a blend of strategic planning and randomness. While unit statistics and player decisions play a significant role, the combat system incorporates elements of randomness through dice rolls.","title":"Project Background"},{"location":"ti4_combat_simulator/#project-overview","text":"This combat simulator for TI4 utilizes Monte Carlo and probability theory to model the distribution of outcomes for in-game combat scenarios. This tool helps players understand the potential outcomes of their strategic decisions in combat, aiding in planning and execution during gameplay.","title":"Project Overview"},{"location":"ti4_combat_simulator/#key-features","text":"Monte Carlo simulation methods to predict combat outcomes. Probability theory to sample from combinations of probabilities.","title":"Key Features"},{"location":"ti4_combat_simulator/#ti4_functions","text":"This document describes a set of functions for simulating combat scenarios using JAX.","title":"ti4_functions"},{"location":"ti4_combat_simulator/#imports","text":"import jax import jax.numpy as jnp from jax import random import os from typing import Dict, Tuple, Any","title":"Imports"},{"location":"ti4_combat_simulator/#types","text":"KeyType = Tuple[int, float] SideType = Dict[KeyType, int] RNGKey = Any","title":"Types"},{"location":"ti4_combat_simulator/#functions","text":"","title":"Functions"},{"location":"ti4_combat_simulator/#apply_hits","text":"def apply_hits(side: SideType, hits_scored: int, rng_key: RNGKey) -> SideType: \"\"\" Apply hits to a side with JAX, prioritizing dice with lower hit probabilities and lower health. Incorporates randomness in selecting dice within the same priority level to take hits. Accepts an RNG key for reproducible randomness. Parameters: side (SideType): Dictionary representing the side's units and their stats. hits_scored (int): Number of hits to apply to the side. rng_key (RNGKey): JAX random key for generating random numbers. Returns: SideType: Updated side after applying hits. \"\"\"","title":"apply_hits"},{"location":"ti4_combat_simulator/#simulate_combat_round_jax","text":"def simulate_combat_round_jax(side_a: SideType, side_b: SideType, rng_key: RNGKey) -> Tuple[SideType, SideType]: \"\"\" Simulates a single round of combat between two sides using JAX. Parameters: side_a (SideType): First combatant side. side_b (SideType): Second combatant side. rng_key (RNGKey): JAX random key for generating random numbers. Returns: Tuple[SideType, SideType]: Updated states of side_a and side_b after combat. \"\"\"","title":"simulate_combat_round_jax"},{"location":"ti4_combat_simulator/#run_combat_until_elimination","text":"def simulate_combat_round_jax(side_a: SideType, side_b: SideType, rng_key: RNGKey) -> Tuple[SideType, SideType]: \"\"\" Simulates a single round of combat between two sides using JAX. Parameters: side_a (SideType): First combatant side. side_b (SideType): Second combatant side. rng_key (RNGKey): JAX random key for generating random numbers. Returns: Tuple[SideType, SideType]: Updated states of side_a and side_b after combat. \"\"\"","title":"run_combat_until_elimination"},{"location":"ti4_combat_simulator/#monte_carlo_combat_simulation","text":"def monte_carlo_combat_simulation(initial_side_a: SideType, initial_side_b: SideType, num_simulations: int = 1000) -> Dict[str, float]: \"\"\" Performs a Monte Carlo simulation of combat between two sides over a specified number of simulations to estimate outcome probabilities. Parameters: initial_side_a (SideType): Initial state of side A. initial_side_b (SideType): Initial state of side B. num_simulations (int): Number of simulations to run. Returns: Dict[str, float]: Probabilities of different outcomes. \"\"\"","title":"monte_carlo_combat_simulation"},{"location":"ti4_combat_simulator/#example-usage","text":"The following is an example of 2 dreadnaughts, each with 2 health hitting 60% of the time fighting vs 6 fighters, each with 1 health hitting 20% of the time. initial_side_a = {(2, 0.6): 3} initial_side_b = {(1, 0.2): 6} num_simulations = 10000 probabilities = monte_carlo_combat_simulation(initial_side_a, initial_side_b, num_simulations) print(probabilities)","title":"Example Usage"}]}